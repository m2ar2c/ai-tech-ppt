## 四、机器学习底层逻辑基础

### 4.1 机器学习的基本分类

机器学习是人工智能的核心技术之一，主要分为三大类：**监督学习、无监督学习和强化学习**。

\*\* 监督学习（Supervised Learning）\*\* 是机器学习中最常见的类型，其核心思想是通过已知的输入和输出数据对模型进行训练，使模型能够学习到输入和输出之间的映射关系。监督学习使用带标签的训练数据，每个样本都包含输入特征和对应的输出标签。

监督学习主要应用于：



* **分类任务**：将输入数据划分到预定义的类别中，如垃圾邮件检测、图像识别、手写数字识别等

* **回归任务**：预测一个连续的数值，如房价预测、股票价格预测、温度预测等

常见的监督学习算法包括：



* 线性回归（Linear Regression）

* 逻辑回归（Logistic Regression）

* 支持向量机（SVM）

* 决策树（Decision Tree）

* 随机森林（Random Forest）

* 神经网络（Neural Network）

\*\* 无监督学习（Unsupervised Learning）\*\* 是一种不需要标记数据的机器学习方法，其目标是通过分析数据的内在结构和分布，发现数据中的隐藏模式和规律。无监督学习的数据没有标签，算法需要自主发现数据的结构或聚类。

无监督学习主要应用于：



* **聚类（Clustering）**：将数据划分为若干个簇，使同一簇内的数据相似度高，不同簇内的数据相似度低，如客户细分、图像分割等

* **降维（Dimensionality Reduction）**：通过减少数据的特征维度，降低数据的复杂度，同时保留数据的主要信息，如主成分分析（PCA）、t-SNE 等

* **异常检测（Anomaly Detection）**：识别数据中的异常点或离群点，如信用卡欺诈检测、网络入侵检测等

常见的无监督学习算法包括：



* K-Means 聚类

* DBSCAN 密度聚类

* 主成分分析（PCA）

* t-SNE 非线性降维

* 自编码器（Autoencoder）

\*\* 强化学习（Reinforcement Learning）\*\* 是一种通过与环境交互来学习最优行为策略的机器学习方法。在强化学习中，智能体（Agent）通过观察环境的状态（State），选择一个动作（Action），并根据环境的反馈（Reward）来调整其行为策略，以最大化累积奖励。

强化学习广泛应用于：



* 机器人控制（如路径规划、抓取物体）

* 游戏（如 AlphaGo、AlphaStar）

* 资源管理（如电力调度、网络流量管理）

* 推荐系统（如个性化推荐）

常见的强化学习算法包括：



* Q-Learning

* SARSA

* 深度 Q 网络（DQN）

* 策略梯度（Policy Gradient）

* 演员 - 评论家（Actor-Critic）

### 4.2 深度学习的核心原理

深度学习是机器学习的一个分支，它通过构建具有多个层次的神经网络来学习数据的复杂模式。**神经网络**是深度学习的基础，由大量的神经元相互连接组成。

**人工神经网络结构**：

典型的神经网络包含三个层次：



1. **输入层**：接收原始数据输入

2. **隐藏层**：包含多个神经元，进行特征提取和变换

3. **输出层**：产生最终的预测结果

每个神经元都包含一个**激活函数（Activation Function）**，它的作用是向神经网络中引入非线性因素。如果没有激活函数，无论多少层神经网络都只能表示线性变换，无法学习复杂的非线性关系。

常用的激活函数包括：



* **Sigmoid 函数**：$f(x) = \frac{1}{1 + e^{-x}}$，将任意实数输入压缩到 (0, 1) 区间，常用于二分类问题的输出层

* **ReLU 函数**：$f(x) = \max(0, x)$，是目前最常用的隐藏层激活函数，具有计算简单、不易梯度消失等优点

* **Softmax 函数**：用于多分类问题，将输出转换为概率分布

**前向传播与反向传播**：



* **前向传播**：数据从输入层经过隐藏层传递到输出层，计算出预测值

* **反向传播（Backpropagation）**：基于链式法则，从输出层逆向计算误差并逐层传递到输入层，计算损失函数对每个参数的梯度，然后利用梯度下降法更新网络权重

反向传播算法的核心步骤：



1. 计算输出层与目标值之间的误差

2. 通过链式法则计算每层参数对总损失的贡献（梯度）

3. 根据梯度更新权重和偏置

4. 重复迭代直到收敛或达到最大迭代次数

### 4.3 损失函数与优化算法

\*\* 损失函数（Loss Function）\*\* 用于衡量模型预测值与真实值之间的差距，是模型训练的目标函数。不同的任务需要使用不同的损失函数：

**回归任务常用损失函数**：



* **均方误差（MSE）**：$\text{MSE} = \frac{1}{n}\sum_{i=1}^n (y_i - \hat{y}_i)^2$


  * 优点：简单直观，梯度计算简单

  * 缺点：对异常值敏感

**分类任务常用损失函数**：



* **交叉熵损失（Cross-Entropy Loss）**：


  * 二分类：$L = -[y\log(\hat{y}) + (1-y)\log(1-\hat{y})]$

  * 多分类：$L = -\sum_{i=1}^n y_i\log(\hat{y}_i)$

  * 优点：当神经网络最后一层使用 sigmoid 或 softmax 激活函数时，交叉熵损失可以解决梯度消失问题，且与 softmax 配合时反向传播计算高效

**优化算法**的目标是找到使损失函数最小化的模型参数。最基础的优化算法是**梯度下降（Gradient Descent）**，其基本思想是通过沿着梯度下降的方向更新参数，逐步将损失函数最小化。

梯度下降的参数更新公式为：

$\theta_{t+1} = \theta_t - \eta\nabla_\theta J(\theta_t)$

其中，$\theta$是模型参数，$\eta$是学习率，$\nabla_\theta J(\theta_t)$是损失函数对参数的梯度。

常见的梯度下降变体包括：



* **随机梯度下降（SGD）**：每次使用一个样本计算梯度

* **批量梯度下降（Batch Gradient Descent）**：使用全部样本计算梯度

* **小批量梯度下降（Mini-Batch Gradient Descent）**：使用部分样本计算梯度

为了提高收敛速度和稳定性，还发展出了多种改进算法：



* **动量法（Momentum）**：引入动量因子，加速参数更新并减少震荡

* **RMSprop**：使用指数衰减平均值减少梯度的方差

* **Adam**：结合了动量法和 RMSprop 的优点，是目前最常用的优化算法之一

### 4.4 过拟合与正则化技术

\*\* 过拟合（Overfitting）\*\* 是机器学习中的常见问题，指模型在训练数据上表现很好，但在测试数据上表现很差的现象。过拟合的原因通常是模型过于复杂，学习到了训练数据中的噪声和细节，而没有学习到通用的模式。

过拟合的表现：



* 训练集损失很低，验证集损失很高

* 模型对训练数据的微小变化非常敏感

* 在新数据上的泛化能力差

\*\* 正则化（Regularization）\*\* 是防止过拟合的重要技术，通过在损失函数中添加惩罚项来限制模型的复杂度：

**L2 正则化（权重衰减）**：

在损失函数中添加权重的 L2 范数作为惩罚项：

$L = L_{loss} + \lambda\sum_i w_i^2$

其中，$\lambda$是正则化参数，控制惩罚的强度。L2 正则化倾向于产生较小的权重，使模型更加平滑。

**L1 正则化**：

使用权重的 L1 范数作为惩罚项：

$L = L_{loss} + \lambda\sum_i |w_i|$

L1 正则化倾向于产生稀疏的权重，即很多权重为 0，从而实现特征选择的效果。

除了正则化，其他防止过拟合的方法还包括：



* **早停法（Early Stopping）**：当验证集损失不再改善时停止训练

* **dropout**：随机失活部分神经元，减少神经元之间的依赖

* **数据增强**：通过对训练数据进行变换增加数据量

* **集成学习**：组合多个模型的预测结果